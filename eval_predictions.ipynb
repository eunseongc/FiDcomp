{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from xopen import xopen\n",
    "from tqdm import tqdm\n",
    "chatgpt_tok = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.1 336.67419962335214\n",
      "0.3 0.2 344.87909604519774\n",
      "0.3 0.3 356.505461393597\n",
      "0.3 0.4 372.5853107344633\n",
      "0.3 0.5 391.9736346516008\n",
      "0.3 0.6 415.9721280602636\n",
      "0.3 0.7 445.894538606403\n",
      "0.3 0.8 483.5303201506591\n",
      "0.3 0.9 533.2305084745763\n",
      "0.3 1.0 592.3461393596987\n",
      "0.4 0.1 448.06704331450095\n",
      "0.4 0.2 464.9306967984934\n",
      "0.4 0.3 486.7551789077213\n",
      "0.4 0.4 516.6429378531074\n",
      "0.4 0.5 550.3600753295668\n",
      "0.4 0.6 589.8210922787194\n",
      "0.4 0.7 636.6455743879472\n",
      "0.4 0.8 693.0463276836158\n",
      "0.4 0.9 761.6267419962335\n",
      "0.4 1.0 837.9969868173258\n",
      "0.5 0.1 583.867043314501\n",
      "0.5 0.2 611.3280602636535\n",
      "0.5 0.3 648.1303201506591\n",
      "0.5 0.4 691.8757062146892\n",
      "0.5 0.5 740.6237288135593\n",
      "0.5 0.6 797.1947269303201\n",
      "0.5 0.7 861.8941619585687\n",
      "0.5 0.8 938.709604519774\n",
      "0.5 0.9 1027.3495291902072\n",
      "0.5 1.0 1122.6715630885121\n",
      "0.6 0.1 741.4282485875706\n",
      "0.6 0.2 779.6621468926554\n",
      "0.6 0.3 831.090395480226\n",
      "0.6 0.4 891.9299435028248\n",
      "0.6 0.5 956.6346516007533\n",
      "0.6 0.6 1030.14802259887\n",
      "0.6 0.7 1115.2354048964219\n",
      "0.6 0.8 1212.4290018832392\n",
      "0.6 0.9 1323.1325800376649\n",
      "0.6 1.0 1439.6760828625236\n"
     ]
    }
   ],
   "source": [
    "for ctx_score_cumsum in [0.3, 0.4, 0.5, 0.6]:\n",
    "    for sent_low in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "        with xopen(f\"compressed_qa_predictions/nq_20/dpr_20_fid_doc{ctx_score_cumsum}_sl{sent_low}_sh1.0_tl1.0-Llama-2-13b-chat-hf-predictions.jsonl.gz\") as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            len_list = []\n",
    "            for pred in preds:\n",
    "                len_list.append(len(chatgpt_tok.encode(pred['compressed_prompt'])))\n",
    "            print(ctx_score_cumsum, sent_low, np.mean(len_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('token_scores/token_scores_list_20_documents_gold_at_0_oneContextFalse.pkl', 'rb') as f:\n",
    "    token_scores_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 192)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(token_scores_list_9[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 192)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(token_scores_list[0][0]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
