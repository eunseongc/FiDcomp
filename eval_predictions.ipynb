{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from xopen import xopen\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from typing import List\n",
    "import regex\n",
    "chatgpt_tok = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s: str) -> str:\n",
    "    \"\"\"Normalization from the SQuAD evaluation script.\n",
    "\n",
    "    See https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
    "    \"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return regex.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def best_subspan_em(prediction: str, ground_truths: List[str]) -> float:\n",
    "    normalized_prediction = normalize_answer(prediction)\n",
    "\n",
    "    for ground_truth in ground_truths:\n",
    "        normalized_ground_truth = normalize_answer(ground_truth)\n",
    "        if normalized_ground_truth.lower() in normalized_prediction.lower():\n",
    "            return 1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'compressed_qa_predictions/nq_20/dpr_20_fid_doc0.3_sl0.1_sh1.0_tl1.0-Llama-2-13b-chat-hf-predictions.jsonl.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ctx_score_cumsum \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sent_low \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mxopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompressed_qa_predictions/nq_20/dpr_20_fid_doc\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mctx_score_cumsum\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_sl\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msent_low\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_sh1.0_tl1.0-Llama-2-13b-chat-hf-predictions.jsonl.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m             preds \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[1;32m      5\u001b[0m             len_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xopen/__init__.py:851\u001b[0m, in \u001b[0;36mxopen\u001b[0;34m(filename, mode, compresslevel, threads, encoding, errors, newline, format)\u001b[0m\n\u001b[1;32m    848\u001b[0m     detected_format \u001b[38;5;241m=\u001b[39m _detect_format_from_content(filename)\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgz\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 851\u001b[0m     opened_file \u001b[38;5;241m=\u001b[39m \u001b[43m_open_gz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m detected_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxz\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    853\u001b[0m     opened_file \u001b[38;5;241m=\u001b[39m _open_xz(filename, binary_mode, compresslevel, threads)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/xopen/__init__.py:579\u001b[0m, in \u001b[0;36m_open_gz\u001b[0;34m(filename, mode, compresslevel, threads)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threads \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# Igzip level 0 does not output uncompressed deflate blocks as zlib does\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;66;03m# and level 3 is slower but does not compress better than level 1 and 2.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m igzip_threaded \u001b[38;5;129;01mand\u001b[39;00m (compresslevel \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode):\n\u001b[0;32m--> 579\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43migzip_threaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    580\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gzip_ng_threaded \u001b[38;5;129;01mand\u001b[39;00m zlib_ng:\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m gzip_ng_threaded\u001b[38;5;241m.\u001b[39mopen(\n\u001b[1;32m    587\u001b[0m             filename,\n\u001b[1;32m    588\u001b[0m             mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m             threads\u001b[38;5;241m=\u001b[39mthreads \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(_available_cpu_count(), \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m    593\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/isal/igzip_threaded.py:61\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline, threads, block_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m             threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m     60\u001b[0m     gzip_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedReader(\n\u001b[0;32m---> 61\u001b[0m         \u001b[43m_ThreadedGzipReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     gzip_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedWriter(\n\u001b[1;32m     64\u001b[0m         _ThreadedGzipWriter(\n\u001b[1;32m     65\u001b[0m             filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m         buffer_size\u001b[38;5;241m=\u001b[39mblock_size\n\u001b[1;32m     72\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/isal/igzip_threaded.py:92\u001b[0m, in \u001b[0;36m_ThreadedGzipReader.__init__\u001b[0;34m(self, filename, queue_size, block_size)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, queue_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, block_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m):\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosefd \u001b[38;5;241m=\u001b[39m \u001b[43mopen_as_binary_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;241m=\u001b[39m igzip\u001b[38;5;241m.\u001b[39m_IGzipReader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, buffersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m block_size)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/isal/igzip_threaded.py:80\u001b[0m, in \u001b[0;36mopen_as_binary_stream\u001b[0;34m(filename, open_mode)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_as_binary_stream\u001b[39m(filename, open_mode):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__fspath__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 80\u001b[0m         binary_file \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopen_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m         closefd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'compressed_qa_predictions/nq_20/dpr_20_fid_doc0.3_sl0.1_sh1.0_tl1.0-Llama-2-13b-chat-hf-predictions.jsonl.gz'"
     ]
    }
   ],
   "source": [
    "for ctx_score_cumsum in [0.3, 0.4, 0.5, 0.6]:\n",
    "    for sent_low in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "        with xopen(f\"compressed_qa_predictions/nq_20/dpr_20_fid_doc{ctx_score_cumsum}_sl{sent_low}_sh1.0_tl1.0-Llama-2-13b-chat-hf-predictions.jsonl.gz\") as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            len_list = []\n",
    "            for pred in preds:\n",
    "                len_list.append(len(chatgpt_tok.encode(pred['compressed_prompt'])))\n",
    "            print(ctx_score_cumsum, sent_low, np.mean(len_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('token_scores/token_scores_list_20_documents_gold_at_0_oneContextFalse.pkl', 'rb') as f:\n",
    "    token_scores_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(token_scores_list_9[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(x):\n",
    "    mean_absolute_diff = np.abs(np.subtract.outer(x, x)).mean()\n",
    "    relative_mean_absolute_diff = mean_absolute_diff/np.mean(x)\n",
    "    g = 0.5 * relative_mean_absolute_diff\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with xopen('compressed_qa_predictions/dpr_nq_20_dev_20/fid_500_ctxTrue_sentTrue0.15_tokFalse1.0_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "#     preds = [json.loads(l) for l in f]\n",
    "# FiDcomp/\n",
    "with xopen('compressed_qa_predictions/dpr_nq_20/dpr_20_fid_doc0.4_sl0.3_sh1.0_tl1.0-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    preds_old = [json.loads(l) for l in f]\n",
    "with xopen(f'compressed_qa_predictions/base/0527_adaptive_ctx_score_v3_power4/dpr_nq_test_20/fid_500_ctxTrue_sentTrue0.15_4_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "    preds_new = [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qas_i = 5\n",
    "\n",
    "gold_answers = preds_old[qas_i][\"answers\"]\n",
    "print(preds_old[qas_i]['compressed_prompt'], preds_old[qas_i]['model_answer'], best_subspan_em(prediction=preds_old[qas_i]['model_answer'], ground_truths=preds_old[qas_i][\"answers\"]))\n",
    "print()\n",
    "print(preds_new[qas_i]['compressed_prompt'], preds_new[qas_i]['model_answer'], best_subspan_em(prediction=preds_new[qas_i]['model_answer'], ground_truths=preds_old[qas_i][\"answers\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_new[0]['compressed_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_preds = []\n",
    "span_em_list_old, span_em_list_new = [], []\n",
    "for qas_i, pred_old, pred_new in enumerate(zip(preds_old, preds_new)):\n",
    "    gold_answers = pred_old[\"answers\"]\n",
    "    model_answer = pred_old[\"model_answer\"]\n",
    "    span_em_old = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "    span_em_list_old.append(span_em_old)\n",
    "\n",
    "    gold_answers = pred_new[\"answers\"]\n",
    "    model_answer = pred_new[\"model_answer\"]\n",
    "    span_em_new = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "    span_em_list_new.append(span_em_new)\n",
    "    if span_em_old and not span_em_new:\n",
    "        diff_preds.append(qas_i)\n",
    "    # span_em_list.append(span_em)\n",
    "\n",
    "print(\"OLD:\", f\"{np.mean(span_em_list_old)*100:.2f}\", \"NEW:\", f\"{np.mean(span_em_list_new)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_preds[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_preds[0][0]['ctxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_preds[0][0]['compressed_prompt']), print(diff_preds[0][1]['compressed_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_indices = {}\n",
    "for gini in [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 'mean']:\n",
    "    with open(f'gini_low_{gini}_indices.pkl', 'rb') as f:\n",
    "        gini_low_indices = pickle.load(f)\n",
    "        low_indices[gini] = gini_low_indices\n",
    "\n",
    "low_indices_entropy = {}\n",
    "for entropy in ['mean']:\n",
    "    with open(f'entropy_low_{gini}_indices.pkl', 'rb') as f:\n",
    "        entropy_low_indices = pickle.load(f)\n",
    "        low_indices_entropy[entropy] = set(entropy_low_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_indices = set()\n",
    "with open('qa_data/dpr_nq_test.json') as f:\n",
    "    test2655 = json.load(f)\n",
    "with open('../eun_FiD/open_domain_data/nq/test.json') as f:\n",
    "    test3610 = json.load(f)\n",
    "for qas in test2655:\n",
    "    for qas_i in range(len(test3610)):\n",
    "        if qas['question'] == test3610[qas_i]['question']:\n",
    "            q_indices.add(qas_i)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(q_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NQ test 3610 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Test 평가\n",
    "version='0601_reader_base'\n",
    "for power in [2, 3, 4]:\n",
    "    sent_ratio_list = [0.1, 0.15, 0.2]\n",
    "    for sent_ratio in sent_ratio_list:\n",
    "        with xopen(f'compressed_qa_predictions/base/{version}/dpr_nq_test3610_20/fid_500_ctxTrue_sentTrue{sent_ratio}_{power}_sent1False_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            span_em_list = []\n",
    "            span_em_list_2655 = []\n",
    "            for pred_i, pred in enumerate(preds):\n",
    "                gold_answers = pred[\"answers\"]\n",
    "                model_answer = pred[\"model_answer\"]\n",
    "                span_em = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "                span_em_list.append(span_em)\n",
    "                if pred_i in q_indices:\n",
    "                    span_em_list_2655.append(span_em)\n",
    "            \n",
    "            print(f\"3610 sent_ratio{sent_ratio} {power} {np.mean(span_em_list)*100:.2f} {np.mean(span_em_list_2655)*100:.2f}\")\n",
    "    ctx_cumsum_list= [0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "    for cumsum in ctx_cumsum_list:\n",
    "        with xopen(f'compressed_qa_predictions/base/{version}/dpr_nq_test3610_20/fid_500_ctxTrue{cumsum}_sentTrue_{power}_sent1False_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            span_em_list = []\n",
    "            span_em_list_2655 = []\n",
    "            for pred_i, pred in enumerate(preds):\n",
    "                gold_answers = pred[\"answers\"]\n",
    "                model_answer = pred[\"model_answer\"]\n",
    "                span_em = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "                span_em_list.append(span_em)\n",
    "                if pred_i in q_indices:\n",
    "                    span_em_list_2655.append(span_em)\n",
    "            \n",
    "            print(f\"3610 cumsum{cumsum} {power} {np.mean(span_em_list)*100:.2f} {np.mean(span_em_list_2655)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_ratio0.1 2 67.721281\n",
      "sent_ratio0.15 2 67.495292\n",
      "sent_ratio0.2 2 67.645951\n",
      "sent_ratio0.25 2 67.645951\n"
     ]
    }
   ],
   "source": [
    "################# Test2655 평가\n",
    "gini2span_em_list_low_mean = defaultdict(list)\n",
    "gini2span_em_list_high_mean = defaultdict(list)\n",
    "version='0601_reader_base_solvedtitleinsentsissue'\n",
    "dataset = 'dpr_nq_test_20'\n",
    "for power in [2]:\n",
    "    sent_ratio_list = [0.1, 0.15, 0.2, 0.25]\n",
    "    for sent_ratio in sent_ratio_list:\n",
    "        with xopen(f'compressed_qa_predictions/base/{version}/{dataset}/fid_500_ctxTrue_sentTrue{sent_ratio}_{power}_sent1False_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            span_em_list = []\n",
    "            gini2span_em_list_low = defaultdict(list)\n",
    "            gini2span_em_list_high = defaultdict(list)\n",
    "\n",
    "            for pred_i, pred in enumerate(preds):\n",
    "                gold_answers = pred[\"answers\"]\n",
    "                model_answer = pred[\"model_answer\"]\n",
    "                span_em = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "                span_em_list.append(span_em)\n",
    "            \n",
    "                for gini, gini_indices in low_indices.items():\n",
    "                    if pred_i in gini_indices:\n",
    "                        gini2span_em_list_low[gini].append(span_em)\n",
    "                    else:\n",
    "                        gini2span_em_list_high[gini].append(span_em)\n",
    "                        \n",
    "            for gini, span_em_list_low in gini2span_em_list_low.items():\n",
    "                gini2span_em_list_low_mean[gini].append(np.mean(span_em_list_low))\n",
    "            for gini, span_em_list_high in gini2span_em_list_high.items():\n",
    "                gini2span_em_list_high_mean[gini].append(np.mean(span_em_list_high))\n",
    "\n",
    "            print(f\"sent_ratio{sent_ratio} {power} {np.mean(span_em_list)*100:.6f}\")\n",
    "            \n",
    "# for power in [2, 3, 4]:\n",
    "#     ctx_cumsum_list= [0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "#     for cumsum in ctx_cumsum_list:\n",
    "#         with xopen(f'compressed_qa_predictions/base/{version}/{dataset}/fid_500_ctxTrue{cumsum}_sentTrue_{power}_sent1False_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "#             preds = [json.loads(l) for l in f]\n",
    "#             span_em_list = []\n",
    "#             for pred_i, pred in enumerate(preds):\n",
    "#                 gold_answers = pred[\"answers\"]\n",
    "#                 model_answer = pred[\"model_answer\"].split('\\n')[0]\n",
    "#                 span_em = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "#                 span_em_list.append(span_em)\n",
    "            \n",
    "#             print(f\"cumsum{cumsum} {power} {np.mean(span_em_list)*100:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0.3: [0.6846573681018799,\n",
       "              0.6858702243784112,\n",
       "              0.6858702243784112,\n",
       "              0.6852637962401456],\n",
       "             0.35: [0.6809787626962143,\n",
       "              0.6800554016620498,\n",
       "              0.6805170821791321,\n",
       "              0.6791320406278855],\n",
       "             0.4: [0.6778846153846154,\n",
       "              0.6754807692307693,\n",
       "              0.6778846153846154,\n",
       "              0.6770833333333334],\n",
       "             0.25: [0.688780487804878,\n",
       "              0.6878048780487804,\n",
       "              0.6897560975609756,\n",
       "              0.686829268292683],\n",
       "             'mean': [0.6881331403762663,\n",
       "              0.6895803183791607,\n",
       "              0.6895803183791607,\n",
       "              0.6888567293777135],\n",
       "             0.15: [0.7476635514018691,\n",
       "              0.7476635514018691,\n",
       "              0.7757009345794392,\n",
       "              0.7757009345794392],\n",
       "             0.2: [0.6997690531177829,\n",
       "              0.6951501154734411,\n",
       "              0.7043879907621247,\n",
       "              0.7066974595842956],\n",
       "             0.1: [0.8, 0.8, 0.8, 0.8]})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini2span_em_list_low_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_indices_recall20 = set()\n",
    "for qas_i, qas in enumerate(dev):\n",
    "    has_answers = [ctx['has_answer'] for ctx in qas['ctxs']]\n",
    "    if sum(has_answers) > 0:\n",
    "        q_indices_recall20.add(qas_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qa_data/dpr_nq_dev.json\") as f:\n",
    "    dev = json.load(f)\n",
    "with open('../eun_FiD/open_domain_data/nq/biencoder-nq-dev.json') as f:\n",
    "    dev_dpr = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qas in dev_dpr:\n",
    "    qas['question_'] = ''.join(qas['question'].replace('--', '_').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8757/8757 [00:06<00:00, 1432.46it/s]\n"
     ]
    }
   ],
   "source": [
    "q_indices_dev_dpr = set()\n",
    "for qas_i, qas in enumerate(tqdm(dev)):\n",
    "    cur_q = ''.join(qas['question'].split())\n",
    "    for i in range(len(dev_dpr)):\n",
    "        if cur_q == dev_dpr[i]['question_']:\n",
    "            if qas_i not in q_indices_dev_dpr:\n",
    "                q_indices_dev_dpr.add(qas_i)\n",
    "                break\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [''.join(dev[qas_i]['question'].split()) for qas_i in q_indices_dev_dpr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the meridian opposite of earth 's prime meridian ( 0 ° longitude ) is called\n",
      "how often does spermatogeneis -- the production of sperm -- occur\n",
      "st. peter 's basilica the head of the catholic religion is located in\n",
      "-- composer arnold schoenberg was highly influential in the movement called --\n",
      "who won the sprint 15km men 's cross country skiing event in sochi in 2014\n",
      "the popular sculpture shiva nataraja depicts shiva -- or siva -- as\n",
      "what was national louis university 's initial area of specialization\n",
      "if two organism 's have the same name in their binomial name then they are in the same\n",
      "which movie has won the best animation award at the 89th academy awards -- 2017\n",
      "name 2 art movements that occurred during the 1920 's\n",
      "what are hare 's two levels of moral thinking\n"
     ]
    }
   ],
   "source": [
    "for qas in dev_dpr:\n",
    "    if qas['question_'] not in questions:\n",
    "        print(qas['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are hare’s two levels of moral thinking\n"
     ]
    }
   ],
   "source": [
    "for qas_i, qas in enumerate(dev):\n",
    "    if 'two levels of moral thinking' in qas['question']:\n",
    "        print(qas['question'])\n",
    "        q_indices_dev_dpr.add(qas_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q_indices_recall20' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dev_q_indices_list \u001b[38;5;241m=\u001b[39m [q_indices_dev_dpr, \u001b[43mq_indices_recall20\u001b[49m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q_indices_recall20' is not defined"
     ]
    }
   ],
   "source": [
    "dev_q_indices_list = [q_indices_dev_dpr, q_indices_recall20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xopen('compressed_qa_data/base/0601_reader_base_solvedtitleinsentsissue/dpr_nq_test_20/fid_500_ctxTrue0.35_sentTrue_2_sent1False_orgidxTrue.jsonl.gz_v1') as f:\n",
    "    data_v1 = [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xopen('compressed_qa_data/base/0601_reader_base_solvedtitleinsentsissue/dpr_nq_test_20/fid_500_ctxTrue0.35_sentTrue_2_sent1False_orgidxTrue.jsonl.gz') as f:\n",
    "    data_v2 = [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qas_i, (qas_1, qas_2) in enumerate(zip(data_v1, data_v2)):\n",
    "    if qas_1['compressed_prompt'] != qas_2['compressed_prompt']:\n",
    "        print(qas_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEV 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_ratio0.1 2 47.790339 53.998465, 77.001256\n",
      "sent_ratio0.15 2 47.824597 54.044513, 76.955578\n",
      "sent_ratio0.2 2 47.801759 54.013814, 76.864223\n",
      "sent_ratio0.25 2 47.756081 54.013814, 76.887062\n",
      "sent_ratio0.1 3 47.698984 53.844973, 76.704351\n",
      "sent_ratio0.15 3 47.721823 53.875672, 76.624415\n",
      "sent_ratio0.2 3 47.824597 54.105909, 76.521640\n",
      "sent_ratio0.25 3 47.858856 54.244052, 76.510220\n",
      "sent_ratio0.1 4 47.995889 54.351497, 76.350348\n",
      "sent_ratio0.15 4 47.836017 54.198005, 76.304671\n",
      "sent_ratio0.2 4 47.607628 53.860322, 76.213315\n",
      "sent_ratio0.25 4 47.539112 53.752878, 76.201896\n",
      "cumsum 0.35 2 59.655133 67.413661, 72.547676\n",
      "cumsum 0.4 2 60.134749 68.089025, 75.151308\n",
      "cumsum 0.45 2 60.351719 68.104375, 76.350348\n",
      "cumsum 0.5 2 60.705721 68.442057, 76.795706\n",
      "cumsum 0.55 2 60.682882 68.273216, 76.875642\n",
      "cumsum 0.6 2 60.214685 67.828089, 76.818545\n",
      "cumsum 0.35 3 59.735069 67.475058, 72.547676\n",
      "cumsum 0.4 3 60.260363 68.288565, 75.117049\n",
      "cumsum 0.45 3 60.214685 68.042978, 76.201896\n",
      "cumsum 0.5 3 60.443074 68.119724, 76.567318\n",
      "cumsum 0.55 3 60.420235 68.058327, 76.555898\n",
      "cumsum 0.6 3 60.123330 67.659248, 76.498801\n",
      "cumsum 0.35 4 59.746489 67.490407, 72.536257\n",
      "cumsum 0.4 4 59.997716 68.058327, 75.014274\n",
      "cumsum 0.45 4 60.340299 68.227168, 75.950668\n",
      "cumsum 0.5 4 60.534430 68.150422, 76.304671\n",
      "cumsum 0.55 4 60.374557 67.950883, 76.373187\n",
      "cumsum 0.6 4 60.180427 67.751343, 76.236154\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "version = '0601_reader_base_solvedtitleinsentsissue'\n",
    "dataset = 'dpr_nq_dev_20'\n",
    "powers = [2, 3, 4]\n",
    "for power in powers:\n",
    "    sent_ratio_list = [0.1, 0.15, 0.2, 0.25]\n",
    "    for sent_ratio in sent_ratio_list:\n",
    "        with xopen(f'compressed_qa_predictions/base/{version}/{dataset}/fid_500_ctxTrue_sentTrue{sent_ratio}_{power}_sent1False_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            span_em_list = []\n",
    "            recall_list = []\n",
    "            span_em_list2 = []\n",
    "            for pred_i, pred in enumerate(preds):\n",
    "                gold_answers = pred[\"answers\"]\n",
    "                model_answer = pred[\"model_answer\"]\n",
    "                span_em = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "                recall = best_subspan_em(prediction=pred['model_prompt'], ground_truths=gold_answers)\n",
    "                span_em_list.append(span_em)\n",
    "                recall_list.append(recall)\n",
    "                if pred_i in q_indices_dev_dpr:\n",
    "                    span_em_list2.append(span_em)\n",
    "            \n",
    "            print(f\"sent_ratio{sent_ratio} {power} {np.mean(span_em_list)*100:.6f} {np.mean(span_em_list2)*100:.6f}, {np.mean(recall_list)*100:.6f}\")\n",
    "            \n",
    "for power in powers:\n",
    "    ctx_cumsum_list= [0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "    for cumsum in ctx_cumsum_list:\n",
    "        with xopen(f'compressed_qa_predictions/base/{version}/{dataset}/fid_500_ctxTrue{cumsum}_sentTrue_{power}_sent1False_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            span_em_list = []\n",
    "            recall_list = []\n",
    "            span_em_list2 = []\n",
    "            for pred_i, pred in enumerate(preds):\n",
    "                gold_answers = pred[\"answers\"]\n",
    "                model_answer = pred[\"model_answer\"]\n",
    "                span_em = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "                recall = best_subspan_em(prediction=pred['model_prompt'], ground_truths=gold_answers)\n",
    "                span_em_list.append(span_em)\n",
    "                recall_list.append(recall)\n",
    "                if pred_i in q_indices_dev_dpr:\n",
    "                    span_em_list2.append(span_em)\n",
    "            \n",
    "            print(f\"cumsum {cumsum} {power} {np.mean(span_em_list)*100:.6f} {np.mean(span_em_list2)*100:.6f}, {np.mean(recall_list)*100:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pow in [4]:\n",
    "    gini2span_em_list_low_mean = defaultdict(list)\n",
    "    gini2span_em_list_high_mean = defaultdict(list)\n",
    "            gini2span_em_list_low = defaultdict(list)\n",
    "            gini2span_em_list_high = defaultdict(list)\n",
    "    entropy2span_em_list_low_mean = defaultdict(list)\n",
    "    entropy2span_em_list_high_mean = defaultdict(list)\n",
    "    rate2num_tokens = defaultdict(list)\n",
    "    # for rate in [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "    for rate in [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "        if rate == 0.0:\n",
    "            sent_comp = False\n",
    "        else:\n",
    "            sent_comp = True\n",
    "        with xopen(f'compressed_qa_predictions/base/0530_ctx_cumsum_pow{pow}/dpr_nq_test_20/fid_500_ctxTrue{rate}_sentTrue_{pow}_sent1False_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "        # with xopen(f'compressed_qa_predictions/base/0527_adaptive_ctx_score_v3_power{pow}_q_include/dpr_nq_test_20/fid_500_ctxTrue_sent{sent_comp}{rate}_{pow}_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            doc_num_list = []\n",
    "            span_em_list = []\n",
    "            gini2span_em_list_low = defaultdict(list)\n",
    "            gini2span_em_list_high = defaultdict(list)\n",
    "\n",
    "            entropy2span_em_list_low = defaultdict(list)\n",
    "            entropy2span_em_list_high = defaultdict(list)\n",
    "\n",
    "            for p_i, pred in enumerate(preds):\n",
    "                rate2num_tokens[str(rate)].append(len(chatgpt_tok.encode(pred['compressed_prompt'])))\n",
    "                cnt = pred['model_prompt'].count('Document [')\n",
    "                doc_num_list.append(cnt)\n",
    "                gold_answers = pred[\"answers\"]\n",
    "                model_answer = pred[\"model_answer\"]\n",
    "                span_em = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "                span_em_list.append(span_em)\n",
    "\n",
    "                for gini, gini_indices in low_indices.items():\n",
    "                    if p_i in gini_indices:\n",
    "                        gini2span_em_list_low[gini].append(span_em)\n",
    "                    else:\n",
    "                        gini2span_em_list_high[gini].append(span_em)\n",
    "\n",
    "                for entropy, entropy_indices in low_indices_entropy.items():\n",
    "                    if p_i in entropy_indices:\n",
    "                        entropy2span_em_list_low[entropy].append(span_em)\n",
    "                    else:\n",
    "                        entropy2span_em_list_high[entropy].append(span_em)\n",
    "                        \n",
    "            for gini, span_em_list_low in gini2span_em_list_low.items():\n",
    "                gini2span_em_list_low_mean[gini].append(np.mean(span_em_list_low))\n",
    "            for gini, span_em_list_high in gini2span_em_list_high.items():\n",
    "                gini2span_em_list_high_mean[gini].append(np.mean(span_em_list_high))\n",
    "\n",
    "            for entropy, span_em_list_low in entropy2span_em_list_low.items():\n",
    "                entropy2span_em_list_low_mean[entropy].append(np.mean(span_em_list_low))\n",
    "            for entropy, span_em_list_high in entropy2span_em_list_high.items():\n",
    "                entropy2span_em_list_high_mean[entropy].append(np.mean(span_em_list_high))\n",
    "\n",
    "            print(f'rate: {rate} num_docs: {np.mean(doc_num_list):.2f} num_tokens: {np.round(np.mean(rate2num_tokens[str(rate)]), 1)} span_em: {100 * np.mean(span_em_list):.4f}')\n",
    "            \n",
    "            # print(f'low ({len(span_em_list_low)}): {100 * np.mean(span_em_list_low):.2f}', end=' ')\n",
    "            # print(f'high ({len(span_em_list_high)}): {100 * np.mean(span_em_list_high):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pow in [4]:\n",
    "    gini2span_em_list_low_mean = defaultdict(list)\n",
    "    gini2span_em_list_high_mean = defaultdict(list)\n",
    "    entropy2span_em_list_low_mean = defaultdict(list)\n",
    "    entropy2span_em_list_high_mean = defaultdict(list)\n",
    "    rate2num_tokens = defaultdict(list)\n",
    "    # for rate in [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "    for rate in [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "        if rate == 0.0:\n",
    "            sent_comp = False\n",
    "        else:\n",
    "            sent_comp = True\n",
    "        with xopen(f'compressed_qa_predictions/base/0530_ctx_cumsum_pow{pow}/dpr_nq_test_20/fid_500_ctxTrue{rate}_sentTrue_{pow}_sent1False_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "        # with xopen(f'compressed_qa_predictions/base/0527_adaptive_ctx_score_v3_power{pow}_q_include/dpr_nq_test_20/fid_500_ctxTrue_sent{sent_comp}{rate}_{pow}_orgidxTrue_Llama-2-13b-chat-hf.jsonl.gz') as f:\n",
    "            preds = [json.loads(l) for l in f]\n",
    "            doc_num_list = []\n",
    "            span_em_list = []\n",
    "            gini2span_em_list_low = defaultdict(list)\n",
    "            gini2span_em_list_high = defaultdict(list)\n",
    "\n",
    "            entropy2span_em_list_low = defaultdict(list)\n",
    "            entropy2span_em_list_high = defaultdict(list)\n",
    "\n",
    "            for p_i, pred in enumerate(preds):\n",
    "                rate2num_tokens[str(rate)].append(len(chatgpt_tok.encode(pred['compressed_prompt'])))\n",
    "                cnt = pred['model_prompt'].count('Document [')\n",
    "                doc_num_list.append(cnt)\n",
    "                gold_answers = pred[\"answers\"]\n",
    "                model_answer = pred[\"model_answer\"]\n",
    "                span_em = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "                span_em_list.append(span_em)\n",
    "\n",
    "                for gini, gini_indices in low_indices.items():\n",
    "                    if p_i in gini_indices:\n",
    "                        gini2span_em_list_low[gini].append(span_em)\n",
    "                    else:\n",
    "                        gini2span_em_list_high[gini].append(span_em)\n",
    "\n",
    "                for entropy, entropy_indices in low_indices_entropy.items():\n",
    "                    if p_i in entropy_indices:\n",
    "                        entropy2span_em_list_low[entropy].append(span_em)\n",
    "                    else:\n",
    "                        entropy2span_em_list_high[entropy].append(span_em)\n",
    "                        \n",
    "            for gini, span_em_list_low in gini2span_em_list_low.items():\n",
    "                gini2span_em_list_low_mean[gini].append(np.mean(span_em_list_low))\n",
    "            for gini, span_em_list_high in gini2span_em_list_high.items():\n",
    "                gini2span_em_list_high_mean[gini].append(np.mean(span_em_list_high))\n",
    "\n",
    "            for entropy, span_em_list_low in entropy2span_em_list_low.items():\n",
    "                entropy2span_em_list_low_mean[entropy].append(np.mean(span_em_list_low))\n",
    "            for entropy, span_em_list_high in entropy2span_em_list_high.items():\n",
    "                entropy2span_em_list_high_mean[entropy].append(np.mean(span_em_list_high))\n",
    "\n",
    "            print(f'rate: {rate} num_docs: {np.mean(doc_num_list):.2f} num_tokens: {np.round(np.mean(rate2num_tokens[str(rate)]), 1)} span_em: {100 * np.mean(span_em_list):.4f}')\n",
    "            \n",
    "            # print(f'low ({len(span_em_list_low)}): {100 * np.mean(span_em_list_low):.2f}', end=' ')\n",
    "            # print(f'high ({len(span_em_list_high)}): {100 * np.mean(span_em_list_high):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "67.5 --> 67.8은 갈 수 있는데 이게 맞나?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate: 0.05 num_docs: 3.84 num_tokens: 484.0 span_em: 66.52\n",
    "rate: 0.1 num_docs: 4.21 num_tokens: 483.0 span_em: 67.38\n",
    "rate: 0.15 num_docs: 4.34 num_tokens: 483.0 span_em: 67.53\n",
    "rate: 0.2 num_docs: 4.34 num_tokens: 482.0 span_em: 67.19\n",
    "rate: 0.25 num_docs: 4.31 num_tokens: 483.0 span_em: 66.97\n",
    "rate: 0.3 num_docs: 4.26 num_tokens: 482.0 span_em: 67.04\n",
    "rate: 0.35 num_docs: 4.23 num_tokens: 482.0 span_em: 67.08\n",
    "rate: 0.4 num_docs: 4.18 num_tokens: 482.0 span_em: 66.97\n",
    "rate: 0.45 num_docs: 4.17 num_tokens: 482.0 span_em: 67.01\n",
    "rate: 0.5 num_docs: 4.13 num_tokens: 482.0 span_em: 66.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy2span_em_list_high_mean['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy2span_em_list_low_mean['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(entropy2span_em_list_high['mean']), len(entropy2span_em_list_low['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gini2span_em_list_high['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini: 0.1 (0.1, 0.1), 67.72\n",
      "gini: 0.15 (0.2, 0.1), 67.83\n",
      "gini: 0.2 (0.25, 0.1), 67.83\n",
      "gini: 0.25 (0.2, 0.1), 67.76\n",
      "gini: 0.3 (0.15, 0.1), 67.80\n",
      "gini: 0.35 (0.1, 0.25), 67.80\n",
      "gini: 0.4 (0.1, 0.1), 67.72\n",
      "gini: mean (0.15, 0.1), 67.80\n"
     ]
    }
   ],
   "source": [
    "rate = [0.1, 0.15, 0.2, 0.25]\n",
    "for gini in [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 'mean']:\n",
    "    score_for_low = max(gini2span_em_list_low_mean[gini]) * len(gini2span_em_list_low[gini])\n",
    "    score_for_high = max(gini2span_em_list_high_mean[gini]) * len(gini2span_em_list_high[gini])\n",
    "    rate_for_low = rate[np.argmax(gini2span_em_list_low_mean[gini])]\n",
    "    rate_for_high = rate[np.argmax(gini2span_em_list_high_mean[gini])]\n",
    "    print(f\"gini: {gini} ({rate_for_low}, {rate_for_high}), {100 * (score_for_low + score_for_high) / 2655:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini2span_em_list_high_mean[0.3], gini2span_em_list_low_mean[0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already defined 'gini2span_em_list_low_mean' and 'gini2span_em_list_high_mean'\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "ginis = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 'mean']\n",
    "x = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "fontsize = 20\n",
    "for i, gini in enumerate(ginis):\n",
    "    low_scores = gini2span_em_list_low_mean[gini]\n",
    "    high_scores = gini2span_em_list_high_mean[gini]\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Plotting the data\n",
    "    ax.plot(x, high_scores, label=f'High coefficient ({len(gini2span_em_list_high[gini])})')\n",
    "    ax.plot(x, low_scores, label=f'Low coefficient ({len(gini2span_em_list_low[gini])})')\n",
    "\n",
    "    # Customizing the y-axis limits to close the gap\n",
    "    high_min = min(high_scores)\n",
    "    high_max = max(high_scores)\n",
    "    low_min = min(low_scores)\n",
    "    low_max = max(low_scores)\n",
    "    \n",
    "    # Find the common range, if overlapping, or close the gap if not\n",
    "    combined_min = min(low_min, high_min)\n",
    "    combined_max = max(low_max, high_max)\n",
    "\n",
    "    # Check if there is overlap\n",
    "    if high_min < low_max and high_max > low_min:\n",
    "        # There is overlap\n",
    "        plot_min = combined_min\n",
    "        plot_max = combined_max\n",
    "    else:\n",
    "        # No overlap, minimize the gap\n",
    "        plot_min = min(high_min, low_min)\n",
    "        plot_max = max(high_max, low_max)\n",
    "\n",
    "    # Reducing vertical space between the two sets of data\n",
    "    buffer = (plot_max - plot_min) * 0.03  # 10% buffer to avoid cutting off peaks\n",
    "    ax.set_ylim(plot_min - buffer, plot_max + buffer)\n",
    "    ## y_tick, x_tick font size\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontsize*.6)\n",
    "\n",
    "    # Setting labels and title\n",
    "    ax.set_xlabel(r'$\\mathcal{R}_H$', fontsize=fontsize)\n",
    "    # ax.set_ylabel('Span EM', fontsize=14)\n",
    "    if gini == 'mean':\n",
    "        ax.set_title(f'Gini: {gini} (NQ dev)', fontsize=fontsize)\n",
    "    else:\n",
    "        ax.set_title(f'Gini: {gini}', fontsize=fontsize)\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(0.32, 0.84), fontsize=fontsize*.6)\n",
    "    # ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
