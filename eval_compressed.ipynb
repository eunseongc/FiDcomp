{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopen import xopen\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import string\n",
    "from typing import List\n",
    "\n",
    "import regex\n",
    "\n",
    "\n",
    "def normalize_answer(s: str) -> str:\n",
    "    \"\"\"Normalization from the SQuAD evaluation script.\n",
    "\n",
    "    See https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
    "    \"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return regex.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def best_subspan_em(prediction: str, ground_truths: List[str]) -> float:\n",
    "    normalized_prediction = normalize_answer(prediction)\n",
    "\n",
    "    for ground_truth in ground_truths:\n",
    "        normalized_ground_truth = normalize_answer(ground_truth)\n",
    "        if normalized_ground_truth.lower() in normalized_prediction.lower():\n",
    "            return 1.0\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = []\n",
    "with open('qa_data/nq-open-oracle-compressed_60.jsonl') as f:\n",
    "    for line in f:\n",
    "        compressed.append(json.loads(line))\n",
    "\n",
    "with xopen('qa_data/nq-open-oracle_60.jsonl.gz', 'w') as f:\n",
    "    for line in tqdm(compressed):\n",
    "        f.write(json.dumps(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_200 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_200.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_200.append(json.loads(line))\n",
    "\n",
    "compressed_190 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_190.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_190.append(json.loads(line))\n",
    "\n",
    "compressed_180 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_180.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_180.append(json.loads(line))\n",
    "\n",
    "compressed_170 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_170.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_170.append(json.loads(line))\n",
    "        \n",
    "compressed_160 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_160.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_160.append(json.loads(line))\n",
    "\n",
    "compressed_150 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_150.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_150.append(json.loads(line))\n",
    "        \n",
    "compressed_140 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_140.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_140.append(json.loads(line))\n",
    "\n",
    "compressed_130 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_130.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_130.append(json.loads(line))\n",
    "\n",
    "compressed_120 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_120.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_120.append(json.loads(line))\n",
    "\n",
    "compressed_100 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_100.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_100.append(json.loads(line))\n",
    "\n",
    "compressed_80 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_80.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_80.append(json.loads(line))\n",
    "\n",
    "compressed_60 = []\n",
    "with xopen('qa_data/oracle_comp/nq-open-oracle-compressed_60.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_60.append(json.loads(line))\n",
    "\n",
    "oracle = []\n",
    "with xopen('qa_data/nq-open-oracle.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        oracle.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_80[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_4 = []\n",
    "with xopen('qa_data/nq-open-oracle_fid_0.4.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        fid_4.append(json.loads(line))\n",
    "\n",
    "fid_5 = []\n",
    "with xopen('qa_data/nq-open-oracle_fid_0.5.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        fid_5.append(json.loads(line))\n",
    "\n",
    "fid_6 = []\n",
    "with xopen('qa_data/nq-open-oracle_fid_0.6.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        fid_6.append(json.loads(line))\n",
    "\n",
    "fid_7 = []\n",
    "with xopen('qa_data/nq-open-oracle_fid_0.7.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        fid_7.append(json.loads(line))\n",
    "\n",
    "fid_8 = []\n",
    "with xopen('qa_data/nq-open-oracle_fid_0.8.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        fid_8.append(json.loads(line))\n",
    "\n",
    "fid_9 = []\n",
    "with xopen('qa_data/nq-open-oracle_fid_0.9.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        fid_9.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_9 = []\n",
    "with xopen('qa_data/nq-open-oracle_fid_0.9_new.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        fid_9.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_tfidf100 = []\n",
    "with xopen('qa_data/nq-open-oracle-compressed-tfidf-1.0.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_tfidf100.append(json.loads(line))\n",
    "\n",
    "compressed_tfidf50 = []\n",
    "with xopen('qa_data/nq-open-oracle-compressed-tfidf-0.5.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_tfidf50.append(json.loads(line))\n",
    "\n",
    "compressed_tfidf20 = []\n",
    "with xopen('qa_data/nq-open-oracle-compressed-tfidf-0.2.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_tfidf20.append(json.loads(line))\n",
    "\n",
    "compressed_tfidf10 = []\n",
    "with xopen('qa_data/nq-open-oracle-compressed-tfidf-0.1.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_tfidf10.append(json.loads(line))\n",
    "\n",
    "compressed_tfidf5 = []\n",
    "with xopen('qa_data/nq-open-oracle-compressed-tfidf-0.05.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        compressed_tfidf5.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_preds_closed = []\n",
    "with xopen('qa_predictions/nq-open-oracle-Llama-2-13b-chat-hf-closedbook-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        llama_preds_closed.append(json.loads(line))\n",
    "\n",
    "llama_preds = []\n",
    "with xopen('qa_predictions/nq-open-oracle-llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        llama_preds.append(json.loads(line))\n",
    "        \n",
    "llama_preds_comp_100 = []\n",
    "with xopen('qa_predictions/nq-open-oracle-compressed-100-Llama-2-13b-chat-hf-predictions.jsonl.gz_2') as f:\n",
    "    for line in f:\n",
    "        llama_preds_comp_100.append(json.loads(line))\n",
    "        \n",
    "# cnt = 0\n",
    "# correct_list = []\n",
    "# correct_compt_list = []\n",
    "qas_indices = []\n",
    "# org_ctx_len = []\n",
    "# comp_ctx_len = []\n",
    "# equal_prompt_diff_ans = []\n",
    "for qas_i, (qas, qas_compressed) in enumerate(tqdm(zip(llama_preds, llama_preds_comp_100))):\n",
    "    pos_ctx = qas['model_prompt'].split('\\n\\n')[2]\n",
    "    comp_pos_ctx = qas_compressed['compressed_prompt'].split('\\n\\n')[1]\n",
    "    if pos_ctx == comp_pos_ctx:\n",
    "        pass\n",
    "    else:\n",
    "        qas_indices.append(qas_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xopen('qa_predictions/20_total_documents/nq-open-20_total_documents_llamactx_fidtoken_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    preds1 = [json.loads(line) for line in f]\n",
    "with xopen('qa_predictions/20_total_documents/nq-open-20_total_documents_gold_at_0_6xcomp_v2-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    preds2 = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided search results, the next Deadpool movie, Deadpool 3, is in development, but there is no official release date announced yet. However, the previous film, Deadpool 2, was released in the United States\n"
     ]
    }
   ],
   "source": [
    "print(preds1[1]['model_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided search results, the next Deadpool movie, Deadpool 3, is currently in development, but there is no official release date announced yet. However, the previous film, Deadpool 2, was released in the United States on May 18, 2018, and it was a critical and commercial success, earning over $365 million worldwide and breaking several records. The film's success has led to the greenlighting of\n"
     ]
    }
   ],
   "source": [
    "print(preds2[1]['model_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "qas_i_list = []\n",
    "for qas_i, (qas, qas_compressed) in enumerate(tqdm(zip(oracle, compressed_200))):\n",
    "    a = \"Document [1](Title: \" + qas['ctxs'][0]['title'] + \") \" + qas['ctxs'][0]['text']\n",
    "    b = qas_compressed['compressed_prompt'].split('\\n\\n')[1]\n",
    "    if a != b:\n",
    "        # if qas_i not in qas_i_list:\n",
    "        #     print(\"qas_i:\", qas_i)\n",
    "        qas_i_list.append(qas_i)\n",
    "    cnt += a==b\n",
    "print(cnt)\n",
    "print(len(qas_i_list))\n",
    "qas_i_set = set(qas_i_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xopen('qa_predictions/20_total_documents/nq-open-20_total_documents_llamactx_fidtoken_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    preds1 = [json.loads(line) for line in f]\n",
    "with xopen('qa_predictions/20_total_documents/nq-open-20_total_documents_gold_at_9_6xcomp_contextonly-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    preds2 = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "<</SYS>>\n",
      "\n",
      "Write a high-quality answer for the given question using only the provided search results (some of which might be irrelevant).\n",
      "\n",
      "Document [7](Title: Nobel Prize in Physics) rendered by the discovery of the remarkable rays (or x-rays). This award is administered by the Nobel Foundation and widely regarded as the most prestigious award that a scientist can receive in physics. It is presented in Stockholm at an annual ceremony on 10 December, the anniversary of Nobel's death. Through 2018, a total of 209 individuals have been awarded the prize. Only three women (1.4% of laureates) have won the Nobel Prize in Physics: Marie Curie in 1903, Maria Goeppert Mayer in 1963, and Donna Strickland in 2018. Alfred Nobel, in his last will and testament, stated that his\n",
      "Document [16](Title: Nobel Prize in Physics) death (1833–1896). Nobel's portrait also appears on the obverse of the Nobel Peace Prize medal and the Medal for the Prize in Economics, but with a slightly different design. The image on the reverse of a medal varies according to the institution awarding the prize. The reverse sides of the Nobel Prize medals for Chemistry and Physics share the same design of Nature, as a Goddess, whose veil is held up by the Genius of Science. These medals and the ones for Physiology/Medicine and Literature were designed by Erik Lindberg in 1902. Nobel laureates receive a diploma directly from the\n",
      "Document [2](Title: List of Nobel laureates in Physics) The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen, of Germany, who received 150,782 SEK, which is equal to 7,731,004 SEK in December 2007.  John Bardeen is the only laureate to win the prize twice—in 1956 and 1972. Maria Skłodowska-Curie also won two Nobel Prizes, for physics in 1903 and chemistry in 1911. William Lawrence Bragg was, until October 2014, the youngest ever Nobel laureate; he won the prize in 1915 at the age of 25. Two women have won the prize: Curie and Maria Goeppert-Mayer (1963). As of 2017, the prize has been awarded\n",
      "Document [13](Title: Nobel Prize) A group including 42 Swedish writers, artists, and literary critics protested against this decision, having expected Leo Tolstoy to be awarded. Some, including Burton Feldman, have criticised this prize because they consider Prudhomme a mediocre poet. Feldman's explanation is that most of the Academy members preferred Victorian literature and thus selected a Victorian poet. The first Physiology or Medicine Prize went to the German physiologist and microbiologist Emil von Behring. During the 1890s, von Behring developed an antitoxin to treat diphtheria, which until then was causing thousands of deaths each year. The first Nobel Peace Prize went to the Swiss\n",
      "\n",
      "Question: who got the first nobel prize in physics\n",
      "Answer: [/INST]\n"
     ]
    }
   ],
   "source": [
    "print(preds1[0]['model_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xopen('qa_predictions/20_total_documents/nq-open-20_total_documents_gold_at_0_6xcomp_contextonly_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f: ## 53.069679849340865\n",
    "    preds1 = [json.loads(line) for line in f]\n",
    "with xopen('qa_predictions/20_total_documents/nq-open-20_total_documents_rev_gold_at_0_6xcomp_contextonly_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f: ## 53.069679849340865\n",
    "    preds2 = [json.loads(line) for line in f]\n",
    "    \n",
    "with xopen('qa_predictions/20_total_documents/nq-open-20_total_documents_llamactx_fidtoken_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f: ## 53.258003766478346\n",
    "    preds3 = [json.loads(line) for line in f]\n",
    "with xopen('qa_predictions/20_total_documents/nq-open-20_total_documents_rev_llamactx_fidtoken_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f: ## 52.73069679849341\n",
    "    preds4 = [json.loads(line) for line in f]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "53.069679849340865\n",
    "53.069679849340865\n",
    "53.258003766478346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -u scripts/evaluate_qa_responses.py --input-path qa_predictions/20_total_documents/nq-open-20_total_documents_gold_at_0_6xcomp_contextonly_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz &&\n",
    "python -u scripts/evaluate_qa_responses.py --input-path qa_predictions/20_total_documents/nq-open-20_total_documents_rev_gold_at_0_6xcomp_contextonly_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz &&\n",
    "python -u scripts/evaluate_qa_responses.py --input-path qa_predictions/20_total_documents/nq-open-20_total_documents_llamactx_fidtoken_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz &&\n",
    "python -u scripts/evaluate_qa_responses.py --input-path qa_predictions/20_total_documents/nq-open-20_total_documents_rev_llamactx_fidtoken_1.0_itself_orgidx-Llama-2-13b-chat-hf-predictions.jsonl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2655/2655 [00:01<00:00, 1812.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.87419962335217 101.96459510357815\n",
      "compress rate: 0.96x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Processing qa_data\n",
    "\n",
    "# compressed_list = [compressed_tfidf100, compressed_tfidf50, compressed_tfidf20, compressed_tfidf10, compressed_tfidf5]\n",
    "# compressed_list = [compressed_200, compressed_190, compressed_180, compressed_170, compressed_160, compressed_150, compressed_140, compressed_130, compressed_120, compressed_100, compressed_80, compressed_60]\n",
    "# compressed_list = [fid_4, fid_5, fid_6, fid_7, fid_8, fid_9]\n",
    "compressed_list = [fid_9]\n",
    "for compressed in compressed_list:\n",
    "    org_ctx_len = []\n",
    "    comp_ctx_len = []\n",
    "    ha_cnt_org, ha_cnt_comp = 0, 0\n",
    "    for qas_i, qas_comp in enumerate(tqdm(compressed)):\n",
    "        # if qas_i not in eval_indices:\n",
    "            # continue\n",
    "        pos_ctx = qas_comp['ctxs'][0]['text']\n",
    "        comp_pos_ctx = qas_comp['ctxs'][0]['compressed_text']\n",
    "        # comp_pos_ctx = qas_comp['compressed_prompt'].split('\\n\\n')[1]\n",
    "        org_ctx_len.append(len(tokenizer.encode(pos_ctx)))\n",
    "        comp_ctx_len.append(len(tokenizer.encode(comp_pos_ctx)))\n",
    "        ## check if compressed ctx has the answer\n",
    "        ha_cnt_org += best_subspan_em(pos_ctx, qas_comp['answers'])\n",
    "        ha_cnt_comp += best_subspan_em(comp_pos_ctx, qas_comp['answers'])\n",
    "    print(np.mean(org_ctx_len), np.mean(comp_ctx_len))\n",
    "    print(f\"compress rate: {1 / (np.mean(org_ctx_len)/np.mean(comp_ctx_len)):.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 27.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for lamb in tqdm([0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]):\n",
    "    lamb_name = str(lamb).replace('.', '')\n",
    "    exec(f'preds_fid_{lamb_name} = []')\n",
    "    with xopen(f'qa_predictions/nq-open-oracle-fid-{lamb}_new-longchat-13b-16k-predictions.jsonl.gz') as f:\n",
    "        for line in f:\n",
    "            exec(f'preds_fid_{lamb_name}.append(json.loads(line))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_fid_sent_3 = []\n",
    "with xopen('qa_predictions/nq-open-oracle-fid_sent_top3-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        preds_fid_sent_3.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_org = []\n",
    "with xopen('qa_predictions/nq-open-oracle-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    for qas_i, line in enumerate(f):\n",
    "        if qas_i in eval_indices:\n",
    "            preds_org.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_fid_04_new = preds_fid_04\n",
    "preds_fid_03_new = preds_fid_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 24.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for topn in tqdm([3, 2, 1]):\n",
    "    topn_name = str(topn).replace('.', '')\n",
    "    exec(f'preds_tfidf_{topn_name} = []')\n",
    "    with xopen(f'qa_predictions/nq-open-oracle-tfidf_sent_top{topn}-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "        for line in f:\n",
    "            exec(f'preds_tfidf_{topn_name}.append(json.loads(line))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreds_tfidf_3\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "preds_tfidf_3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_20_6x_comp = []\n",
    "with open('qa_predictiosn/20_total_documents/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:00<00:00, 1516.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org. context token length: 115.10, compressed: 85.55 (compress rate: 0.74x)\n",
      "Subspan_em: 80.52 (Org. context has answer: 462/462, compressed: 423/462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:00<00:00, 1637.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org. context token length: 115.10, compressed: 67.00 (compress rate: 0.58x)\n",
      "Subspan_em: 76.19 (Org. context has answer: 462/462, compressed: 383/462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:00<00:00, 1785.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org. context token length: 115.10, compressed: 38.58 (compress rate: 0.34x)\n",
      "Subspan_em: 58.87 (Org. context has answer: 462/462, compressed: 264/462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:00<00:00, 2424.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org. context token length: 115.10, compressed: nan (compress rate: nanx)\n",
      "Subspan_em: 85.06 (Org. context has answer: 462/462, compressed: 0/462)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Processing qa_predictions\n",
    "# preds_list = [preds_fid_09, preds_fid_08, preds_fid_07, preds_fid_06, preds_fid_05, preds_fid_04, preds_fid_03, preds_fid_02, preds_fid_01]\n",
    "# preds_list = [preds_fid_03, preds_fid_03_new, preds_fid_04, preds_fid_04_new]\n",
    "preds_list = [preds_tfidf_3, preds_tfidf_2, preds_tfidf_1, preds_org]\n",
    "for preds in preds_list:\n",
    "    org_ctx_len = []\n",
    "    comp_ctx_len = []\n",
    "    em_list = []\n",
    "    ha_cnt_org = 0\n",
    "    ha_cnt_comp = 0\n",
    "    for qas_i, qas_pred in enumerate(tqdm(preds)):\n",
    "        # if qas_i not in eval_indices:\n",
    "            # continue\n",
    "        pos_ctx = qas_pred['ctxs'][0]['text']\n",
    "        if qas_pred['ctxs'][0].get('compressed_text'):\n",
    "            comp_pos_ctx = qas_pred['ctxs'][0]['compressed_text']\n",
    "            comp_ctx_len.append(len(tokenizer.encode(comp_pos_ctx)))\n",
    "            ha_cnt_comp += best_subspan_em(comp_pos_ctx, qas_pred['answers'])\n",
    "        # comp_pos_ctx = qas_pred['compressed_prompt'].split('\\n\\n')[1]\n",
    "        org_ctx_len.append(len(tokenizer.encode(pos_ctx)))\n",
    "        model_answer = qas_pred['model_answer']\n",
    "        # model_answer = qas_pred['model_answer'].split('\\n')[0]\n",
    "        em_list.append(best_subspan_em(model_answer, qas_pred['answers']))\n",
    "        ## check if compressed ctx has the answer\n",
    "        ha_cnt_org += best_subspan_em(pos_ctx, qas_pred['answers'])\n",
    "    print(f\"Org. context token length: {np.mean(org_ctx_len):.2f}, compressed: {np.mean(comp_ctx_len):.2f} (compress rate: {1 / (np.mean(org_ctx_len)/np.mean(comp_ctx_len)):.2f}x)\")\n",
    "    print(f\"Subspan_em: {100*np.mean(em_list):.2f} (Org. context has answer: {int(ha_cnt_org)}/{len(preds)}, compressed: {int(ha_cnt_comp)}/{len(preds)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_subspan_em(preds_fid_9[0]['ctxs'][0]['compressed_text'], preds_fid_9[0]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The's text has been seen by asborative evidence of' policy of the repation of the Jewish people theirivity (an that the Book of attributes to), as the text to the ofaries and repation of. This interpretation has been, as the text only Mesaries, and makes no mention of Jews, Jerusalem, ora. The has also been referred to by, the last Shah of Iran as the first declaration of universal human rights, a view rejected by some as anistic and a of the's as a by a the of.or, of the, has that thethe first a, a andsa of as a of Iran by theh to,ation of the., the Shah's,, the a rep of the. The thatthe of the of human,,, and,, human ['Cyrus']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qas_i = 1\n",
    "print(preds_fid_9[qas_i]['ctxs'][0]['compressed_text'],  preds_fid_9[qas_i]['answers'])\n",
    "best_subspan_em(preds_fid_9[qas_i]['ctxs'][0]['compressed_text'], preds_fid_9[qas_i]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(eval_indices))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Home computers were a class of microcomputers entering the market in 1977, and becoming common during the 1980s.  They were marketed to consumers as affordable and accessible computers that, for the first time, were intended for the use of a single nontechnical user. These computers were a distinct market segment that typically cost much less than business, scientific or engineering-oriented computers of the time such as the IBM PC, and were generally less powerful in terms of memory and expandability. However, a home computer often had better graphics and sound than contemporary business computers. Their most common uses were playing',\n",
       " ['1603'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qas_compressed['ctxs'][0]['text'], qas_preds['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_oa_preds_llama = []\n",
    "# qa_predictions/nq-open-oracle-sent_oa-Llama-2-13b-chat-hf-predictions.jsonl.gz\n",
    "with xopen('qa_predictions/nq-open-oracle-sent_oa-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        sent_oa_preds_llama.append(json.loads(line))\n",
    "\n",
    "sent_oa_preds_longchat = []\n",
    "# qa_predictions/nq-open-oracle-sent_oa-longchat-13b-16k-predictions.jsonl.gz\n",
    "with xopen('qa_predictions/nq-open-oracle-sent_oa-longchat-13b-16k-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        sent_oa_preds_longchat.append(json.loads(line))\n",
    "\n",
    "sent_oa_preds_llama_upstage = []\n",
    "# qa_predictions/nq-open-oracle-sent_oa-llama-30b-instruct-predictions.jsonl.gz\n",
    "with xopen('qa_predictions/nq-open-oracle-sent_oa-llama-30b-instruct-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        sent_oa_preds_llama_upstage.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_preds_llama = []\n",
    "# qa_predictions/nq-open-oracle-oa-Llama-2-13b-chat-hf-predictions.jsonl.gz\n",
    "with xopen('qa_predictions/nq-open-oracle-oa-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        oa_preds_llama.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11737089201877934"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/8.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:00<00:00, 4795.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.96536796536796 14.898268398268398\n",
      "compress rate: 8.52x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:00<00:00, 3782.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.96536796536796 62.125541125541126\n",
      "compress rate: 2.04x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [00:00<00:00, 3879.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.70676691729324 58.18045112781955\n",
      "compress rate: 2.14x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:00<00:00, 3801.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.96536796536796 62.125541125541126\n",
      "compress rate: 2.04x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds_list = [oa_preds_llama, sent_oa_preds_llama, sent_oa_preds_longchat, sent_oa_preds_llama_upstage]\n",
    "for preds in preds_list:\n",
    "    org_ctx_len = []\n",
    "    comp_ctx_len = []\n",
    "    for qas_i, qas in enumerate(tqdm(preds)):\n",
    "        title = qas['ctxs'][0]['title']\n",
    "        text = qas['ctxs'][0]['text']\n",
    "        pos_ctx = f\"Document [1](Title: {title}) {text}\"\n",
    "        \n",
    "        title_rm_answers = qas['ctxs'][0]['title_rm_answers']\n",
    "        text_rm_answers = qas['ctxs'][0]['text_rm_answers']\n",
    "    \n",
    "        comp_pos_ctx = f\"Document [1](Title: {title_rm_answers}) {text_rm_answers}\"\n",
    "        org_ctx_len.append(len(tokenizer.encode(pos_ctx)))\n",
    "        comp_ctx_len.append(len(tokenizer.encode(comp_pos_ctx)))\n",
    "    print(np.mean(org_ctx_len), np.mean(comp_ctx_len))\n",
    "    print(f\"compress rate: {np.mean(org_ctx_len)/np.mean(comp_ctx_len):.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orc_preds = []\n",
    "with xopen('qa_predictions/nq-open-oracle-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        orc_preds.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in [200, 190, 180, 170, 160, 150, 140, 130, 120, 100, 80, 60]:\n",
    "    exec(f'preds_comp_{comp} = []')\n",
    "    with xopen(f'qa_predictions/nq-open-oracle-compressed-{comp}-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "        for line in f:\n",
    "            exec(f'preds_comp_{comp}.append(json.loads(line))')\n",
    "for tfidf in [1.0, 0.5, 0.2, 0.1, 0.05]:\n",
    "    name_tfidf = int(tfidf*100)\n",
    "    exec(f'preds_tfidf_{name_tfidf} = []')\n",
    "    with xopen(f'qa_predictions/nq-open-oracle-compressed-tfidf-{tfidf}-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "        for line in f:\n",
    "            exec(f'preds_tfidf_{name_tfidf}.append(json.loads(line))')\n",
    "\n",
    "# preds_tfidf_100 = []\n",
    "# with xopen(\"qa_predictions/nq-open-oracle-compressed-tfidf-1.0-Llama-2-13b-chat-hf-predictions.jsonl.gz\") as f:\n",
    "#     for line in f:\n",
    "#         preds_tfidf_100.append(json.loads(line))\n",
    "\n",
    "# preds_tfidf_50 = []\n",
    "# with xopen(\"qa_predictions/nq-open-oracle-compressed-tfidf-0.5-Llama-2-13b-chat-hf-predictions.jsonl.gz\") as f:\n",
    "#     for line in f:\n",
    "#         preds_tfidf_50.append(json.loads(line))\n",
    "\n",
    "# preds_tfidf_20 = []\n",
    "# with xopen(\"qa_predictions/nq-open-oracle-compressed-tfidf-0.2-Llama-2-13b-chat-hf-predictions.jsonl.gz\") as f:\n",
    "#     for line in f:\n",
    "#         preds_tfidf_20.append(json.loads(line))\n",
    "        \n",
    "# preds_tfidf_10 = []\n",
    "# with xopen(\"qa_predictions/nq-open-oracle-compressed-tfidf-0.1-Llama-2-13b-chat-hf-predictions.jsonl.gz\") as f:\n",
    "#     for line in f:\n",
    "#         preds_tfidf_10.append(json.loads(line))\n",
    "\n",
    "# preds_tfidf_5 = []\n",
    "# with xopen(\"qa_predictions/nq-open-oracle-compressed-tfidf-0.05-Llama-2-13b-chat-hf-predictions.jsonl.gz\") as f:\n",
    "#     for line in f:\n",
    "#         preds_tfidf_5.append(json.loads(line))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lost_in_the_middle.metrics import best_subspan_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [\"preds_tfidf_5\", \"preds_tfidf_10\", \"preds_tfidf_20\", \"preds_tfidf_50\", \"preds_tfidf_100\"]\n",
    "for preds_name in preds_list:\n",
    "    preds = eval(preds_name)\n",
    "    cnt_1, cnt_2, ans_cnt = 0, 0, 0\n",
    "    for qas in preds:\n",
    "        cnt_1 += best_subspan_em(qas['demonstration'], qas['answer'])\n",
    "        cnt_2 += best_subspan_em(qas['compressed_prompt'], qas['answer'])\n",
    "        ans_cnt += int(best_subspan_em(qas['model_answer'], qas['answer']))\n",
    "    # print(cnt_1, len(preds_tfidf_100))\n",
    "    print(f\"{preds_name} {cnt_2}/{len(preds)}\", f\"{100 * (cnt_2/len(preds)):.2f}% Span EM: {ans_cnt}/{len(preds)}\", f\"{100 * (ans_cnt/len(preds)):.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [\"orc_preds\", \"preds_comp_200\", \"preds_comp_190\", \"preds_comp_180\", \"preds_comp_170\", \"preds_comp_160\", \"preds_comp_150\", \"preds_comp_140\", \"preds_comp_130\", \"preds_comp_120\", \"preds_comp_100\", \"preds_comp_80\", \"preds_comp_60\"]\n",
    "for preds_name in preds_list:\n",
    "    preds = eval(preds_name)\n",
    "    cnt_1, cnt_2, ans_cnt = 0, 0, 0\n",
    "    cnt_3, cnt_4 = [], []\n",
    "    \n",
    "    for qas in preds:\n",
    "        if qas.get('demonstration') is None:\n",
    "            qas['demonstration'] = f\"Document [1](Title: {qas['ctxs'][0]['title']}) {qas['ctxs'][0]['text']}\"\n",
    "        cnt_1 += int(best_subspan_em(qas['demonstration'], qas['answer'])) ## If answer is in the demo (462 out of 462)\n",
    "        \n",
    "        if qas.get('compressed_prompt') is None:\n",
    "            comp_has_answer = 1\n",
    "            pass\n",
    "        else:\n",
    "            comp_has_answer = int(best_subspan_em(qas['compressed_prompt'], qas['answer']))\n",
    "            cnt_2 += comp_has_answer\n",
    "        if comp_has_answer:\n",
    "            cnt_3.append(int(best_subspan_em(qas['model_answer'], qas['answer'])))\n",
    "        else:\n",
    "            cnt_4.append(int(best_subspan_em(qas['model_answer'], qas['answer'])))\n",
    "            \n",
    "        ans_cnt += int(best_subspan_em(qas['model_answer'], qas['answer']))\n",
    "    # print(cnt_1, len(preds_tfidf_100))\n",
    "    print(f\"{preds_name} {cnt_2}/{len(preds)}\", f\"{100 * (cnt_2/len(preds)):.2f}% Span EM: {ans_cnt}/{len(preds)}\", f\"{100 * (ans_cnt/len(preds)):.2f}%, {100 * (np.mean(cnt_3)):.2f}% ({len(cnt_3)}), {100 * (np.mean(cnt_4)):.2f}% ({len(cnt_4)})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xopen('qa_predictions/nq-open-oracle-rm-longchat-13b-16k-predictions.jsonl.gz') as f:\n",
    "    qa_preds = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for idx, qas in enumerate(qa_preds):\n",
    "    if best_subspan_em(qas['model_answer'], qas['answers']):\n",
    "        indices.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_preds[indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 59\n",
    "if int(best_subspan_em(eval(preds_list[-3])[i]['compressed_prompt'], eval(preds_list[-3])[i]['answer'])):\n",
    "    print(eval(preds_list[-3])[i]['compressed_prompt'].split('\\n\\n')[1] == eval(preds_list[-3])[i]['demonstration'])\n",
    "    print(eval(preds_list[-3])[i]['answer'])\n",
    "    print(eval(preds_list[-3])[i]['demonstration'])\n",
    "    print(eval(preds_list[-3])[i]['compressed_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert percentages in A to decimal form for direct comparison\n",
    "A = [97.90, 96.40, 93.70, 93.70, 93.10, 89.50, 87.50, 85.70, 85.40, 80.60, 75.60, 61.60]\n",
    "\n",
    "# Given values for B\n",
    "B = [0.97, 0.96, 0.93, 0.89, 0.85, 0.81, 0.77, 0.74, 0.69, 0.64, 0.6, 0.44]\n",
    "B_percent = [x * 100 for x in B]  # Convert A from percentages to decimals\n",
    "\n",
    "X = [94.3, 92.6, 90.1, 87.0, 84.0, 81.3, 78.1, 75.8, 73.5, 67.6, 60.2, 50.0]\n",
    "# Creating a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X[::-1], A, label='vs. Oracle', marker='o')\n",
    "plt.plot(X[::-1], B_percent, label='Recall@1', marker='x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -u scripts/evaluate_qa_responses.py --input-path qa_predictions/nq-open-oracle-sent_oa-Llama-2-13b-chat-hf-predictions.jsonl.gz &&\n",
    "python -u scripts/evaluate_qa_responses.py --input-path qa_predictions/nq-open-oracle-sent_oa-longchat-13b-16k-predictions.jsonl.gz &&\n",
    "python -u scripts/evaluate_qa_responses.py --input-path qa_predictions/nq-open-oracle-sent_oa-llama-30b-instruct-predictions.jsonl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [\"preds_tfidf_100\", \"preds_tfidf_50\", \"preds_tfidf_20\", \"preds_tfidf_10\", \"preds_tfidf_5\"]\n",
    "for preds_name in preds_list:\n",
    "    preds = eval(preds_name)\n",
    "    cnt_1 = 0\n",
    "    cnt_2 = 0\n",
    "    for qas in preds:\n",
    "        cnt_1 += int(best_subspan_em(qas['demonstration'], qas['answer']))\n",
    "        cnt_2 += int(best_subspan_em(qas['compressed_prompt'], qas['answer']))\n",
    "    # print(cnt_1, len(preds_tfidf_100))\n",
    "    print(f\"{preds_name} {cnt_2}/{len(preds)}\", f\"{100 * (cnt_2/len(preds)):.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for preds in [preds_comp_100, preds_comp_50, preds_comp_20, preds_comp_10, preds_comp_5]:\n",
    "    cnt_1 = 0\n",
    "    cnt_2 = 0\n",
    "    for qas in preds:\n",
    "        cnt_1 += best_subspan_em(qas['demonstration'], qas['answer'])\n",
    "        cnt_2 += best_subspan_em(qas['compressed_prompt'], qas['answer'])\n",
    "        \n",
    "    print(cnt_1, len(preds_tfidf_100))\n",
    "    print(cnt_2, len(preds_tfidf_100), f\"{cnt_2/len(preds_tfidf_100)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "print(len(eval_indices))\n",
    "with open('eval_indices_upstage_llama30b_compressed200.pkl', 'wb') as f:\n",
    "    pickle.dump(eval_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('eval_indices_compressed200.pkl', 'rb') as f:\n",
    "    eval_indices = pickle.load(f)\n",
    "    print(len(eval_indices))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with xopen('qa_predictions/nq-open-oracle-llama-30b-instruct-closedbook-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        preds.append(json.loads(line))\n",
    "        \n",
    "em_list = []\n",
    "closed_correct_indices = set()\n",
    "for i, d in enumerate(preds):\n",
    "    # if i not in real_qas_indices:\n",
    "    #     continue\n",
    "    model_answer = d['model_answer']\n",
    "    # model_answer = model_answer.split('\\n')[0].strip()\n",
    "    gold_answers = d['answers']\n",
    "    correct = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "    if correct:\n",
    "        closed_correct_indices.add(i)\n",
    "    em_list.append(correct)\n",
    "em_array = np.array(em_list)\n",
    "print('EM:', em_array.mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = set(np.arange(2655).tolist())\n",
    "eval_indices = (all_indices - closed_correct_indices) & qas_i_set\n",
    "len(eval_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama_preds_comp_100 = []\n",
    "# with xopen('qa_predictions/nq-open-oracle-compressed-100-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "#     for line in f:\n",
    "#         llama_preds_comp_100.append(json.loads(line))\n",
    "\n",
    "preds = []\n",
    "# with xopen('qa_predictions/nq-open-oracle-longchat-13b-16k-predictions.jsonl.gz') as f:\n",
    "with xopen('qa_predictions/nq-open-oracle-compressed-100-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "# with xopen('qa_predictions/nq-open-oracle-Llama-2-13b-chat-hf-predictions.jsonl.gz') as f:\n",
    "    for line in f:\n",
    "        preds.append(json.loads(line))\n",
    "em_list = []\n",
    "em_list_in_prompt= []\n",
    "for i, d in enumerate(preds):\n",
    "    model_answer = d['model_answer']\n",
    "    # if i in closed_correct_indices:\n",
    "    #     continue\n",
    "    # if i not in qas_i_set:\n",
    "    #     continue\n",
    "    if i not in eval_indices:\n",
    "        continue\n",
    "    # model_answer = model_answer.split('\\n')[0].strip()\n",
    "    gold_answers = d['answer']\n",
    "    correct = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "    correct_in_prompt = best_subspan_em(prediction=d['model_prompt'], ground_truths=gold_answers)\n",
    "    \n",
    "    em_list.append(correct)\n",
    "    em_list_in_prompt.append(correct_in_prompt)\n",
    "    \n",
    "    if correct and not correct_in_prompt:\n",
    "        print(i)\n",
    "        print(d['demonstration'])     \n",
    "        print(d['model_prompt'])\n",
    "        print(model_answer)\n",
    "        print(gold_answers)\n",
    "        break\n",
    "em_array = np.array(em_list)\n",
    "print('EM:', em_array.mean() * 100)\n",
    "print(f'EM: {em_array.mean() * 100:.1f} / # Questions: {em_array.shape[0]}')\n",
    "\n",
    "em_array_in_prompt = np.array(em_list_in_prompt)\n",
    "print('EM:', em_array_in_prompt.mean() * 100)\n",
    "print(f'EM: {em_array_in_prompt.mean() * 100:.1f} / # Questions: {em_array_in_prompt.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token_len in [200, 190, 180, 170, 160, 150, 140, 130, 120, 100, 80, 60]:\n",
    "# for token_len in [200, 180, 160, 140, 120, 100, 80, 60]:\n",
    "\n",
    "for threshold in [0.5, 0.2, 0.1, 0.05]:\n",
    "# for token_len in [200, 180, 160, 140, 120, 100, 80, 60]:\n",
    "    preds = []\n",
    "    with xopen(f'qa_predictions/nq-open-oracle-compressed-{token_len}-llama-30b-instruct-predictions.jsonl.gz') as f:\n",
    "        for line in f:\n",
    "            preds.append(json.loads(line))\n",
    "\n",
    "    em_list = []\n",
    "    for i, d in enumerate(preds):\n",
    "        model_answer = d['model_answer']\n",
    "        # if i in closed_correct_indices:\n",
    "        #     continue\n",
    "        # if i not in qas_i_set:\n",
    "        #     continue\n",
    "        # if i not in eval_indices:\n",
    "        #     continue\n",
    "        # model_answer = model_answer.split('\\n')[0].strip()\n",
    "        gold_answers = d['answer']\n",
    "        correct = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "        em_list.append(correct)\n",
    "    em_array = np.array(em_list)\n",
    "    print(f\"{token_len} {em_array.mean() * 100:.1f}\")\n",
    "    # print(f'EM: {em_array.mean() * 100:.1f} / # Questions: {em_array.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "correct_list = []\n",
    "correct_compt_list = []\n",
    "qas_indices = []\n",
    "org_ctx_len = []\n",
    "comp_ctx_len = []\n",
    "equal_prompt_diff_ans = []\n",
    "for qas_i, (qas, qas_compressed) in enumerate(tqdm(zip(oracle, compressed_180))):\n",
    "    pos_ctx = qas['model_prompt'].split('\\n\\n')[2]\n",
    "    comp_pos_ctx = qas_compressed['compressed_prompt'].split('\\n\\n')[1]\n",
    "    org_ctx_len.append(len(tokenizer.encode(pos_ctx)))\n",
    "    comp_ctx_len.append(len(tokenizer.encode(comp_pos_ctx)))\n",
    "    if pos_ctx == comp_pos_ctx:\n",
    "        # if qas['model_answer'] != qas_compressed['model_answer']:\n",
    "        #     equal_prompt_diff_ans.append((qas, qas_compressed))\n",
    "        cnt += 1\n",
    "    else:\n",
    "        qas_indices.append(qas_i)\n",
    "        # model_answer = qas['model_answer'].split('\\n')[0].strip()\n",
    "        # gold_answers = qas['answers']\n",
    "        # model_answer_comp = qas_compressed['model_answer'].split('\\n')[0].strip()\n",
    "        # correct = best_subspan_em(prediction=model_answer, ground_truths=gold_answers)\n",
    "        # correct_comp = best_subspan_em(prediction=model_answer_comp, ground_truths=gold_answers)\n",
    "        # correct_list.append(correct)\n",
    "        # correct_compt_list.append(correct_comp)\n",
    "        \n",
    "print(cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
